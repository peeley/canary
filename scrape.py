import tweepy, csv, time
from datetime import datetime

# keys generated by Twitter App registration
consumer_key = 'm8RtmPGMWXLOYbSevMwMCxdWQ'
consumer_secret = 'cEnIQGj9yBHvxl6X5Rb8ZekKNoliMk1Eb3H71rp9hE2WzEQ4MB'
access_token = '956820311000969216-BRXHvw9JEJ3TROnPv9UzF2gnLfnzz3r'
access_token_secret = 'zhAcG95RmKwOITjNfFFucStW9aRrdzYVaAiLKYFesIUPb'

# authenticating app with API keys
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)
api = tweepy.API(auth)

# initialises API and relevant variables
user_id = 'realDonaldTrump'
user_posts = api.get_user(id=user_id).statuses_count
tweets = 0
max_id = 0

# opens csv file
tweetwriter = csv.writer(open('data.csv', 'w'), delimiter=',')
tweetwriter.writerow(['ID','Text','Time Posted'])

class Crawler:
	def __init__(self, uid, up, tweetnum, mid, ap):
		self.user_id = uid
		self.user_posts = up
		self.tweets = tweetnum
		self.max_id = mid
		self.api = ap

	# stores tweet id, text, and time posted in csv, prints to console
	def process(self, status):
		tweet = self.api.get_status(status.id, tweet_mode='extended')
		tweet_text = self.trim(tweet._json['full_text'])
		tweet_time = tweet.created_at
		#writes to csv if tweet is not retweet
		if(not (tweet_text[:2] == 'RT')):
			tweetwriter.writerow([tweet.id, tweet_text,tweet_time])	
			print(tweet_text)
			print('\t%s -Tweet #%i, ID:%s\n' % (str(tweet_time), self.tweets, str(tweet.id)))
		self.tweets += 1
		self.max_id = status.id
	
	# trims artifacts of HTML parsing out of tweet text
	def trim(self, str):
		if('http' in str):
			str = str[:str.find('http')]
		if('&amp;' in str):
			str = str.replace('&amp;', 'and')
		if('(' in str):
			str = str.replace('(','-')
		if(')' in str):
			str = str.replace(')','-')
		if('[' in str):
			str = str.replace('[','-')
		if('"' in str):
			str = str.replace('"','')
		if("'" in str):
			str = str.replace("'",'')
		if('”' in str):
			str = str.replace('”','')
		return str
		
	#crawls timeline- after first iteration through timeline, uses max_id
	def crawlTimeline(self,name, last=None):
		try:
			if last is None:
				for status in tweepy.Cursor(self.api.user_timeline,id=name).items():	
					self.process(status)
			else:
				for status in tweepy.Cursor(self.api.user_timeline,max_id=last,id=name).items():
					self.process(status)

		# if API encounter rate limit, waits for 1 minute
		except tweepy.RateLimitError:
				print('rate limit error! waiting from \t'+ str(datetime.now()))
				time.sleep(60)


if __name__ == '__main__':
	crawl = Crawler(user_id,user_posts,tweets,max_id, api)
	while (crawl.tweets < crawl.user_posts):
		if(crawl.tweets == 0):
			crawl.crawlTimeline(crawl.user_id)
		else:
			crawl.crawlTimeline(crawl.user_id, crawl.max_id)	
	print("ALL DONE!!!")

# TODO: 
# problem w/ UTF-8 encoding? "" marks appear even after trimming tweet text
