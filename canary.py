import tweepy, csv, time
from datetime import datetime
from nltk.corpus import stopwords
from nltk.tokenize import TweetTokenizer

# keys generated by Twitter App registration
consumer_key = 'wFRNosYy0eK6ph2pRIKwMybqe'
consumer_secret = 'HU4N6iBn1NqI3LEx7L6hVYsBZp08WfANwBKnzt9hy97gBBiEjp'
access_token = '1287375775-3x7S7mWHVrXkIc8ZFEemRkVCpjdn5aXbhyxKf9H'
access_token_secret = '0kTiFLNlqcuzjGkBH5rz02caxsVYAUPs6WOaoCrWmmMv5'

# authenticating app with API keys
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)
stop_words = set(stopwords.words('english'))

api = tweepy.API(auth)
followers = api.friends
the_donald = api.get_user(screen_name='realDonaldTrump')
real_tweets = 0
tweets = 0
# opens csv file
tweetwriter = csv.writer(open('data.csv', 'w'), delimiter=',')

# processes text with nltk, trims sentences of stop words and media links
def process(str):
	if('http' in str):
			str = str[:str.find('http')]
	tkn = TweetTokenizer()
	sentence = tkn.tokenize(str)
	filtered_sentence = [w for w in sentence if not w in stop_words]
	return (" ".join(filtered_sentence))


for i in tweepy.Cursor(api.user_timeline, id = 'realDonaldTrump').items():
	try:	
		tweet = api.get_status(i.id, tweet_mode='extended')
		tweet_text = process(tweet._json['full_text'])
		tweet_time = tweet.created_at
		
		#writes to csv if tweet is not retweet
		if(not (tweet_text[:2] == 'RT')):
			tweetwriter.writerow([tweet_text,tweet_time])	
			print(tweet_text)
			print('\t %s - Tweet #%i(%i)\n' % (str(tweet_time), real_tweets,tweets))
			real_tweets += 1
			tweets += 1

		else:
			tweets +=1

	except tweepy.RateLimitError:
			print('rate limit error! waiting from \t'+ str(datetime.now()))
			time.sleep(60)	

print("ALL DONE!!!")

# TODO: fix problem w/ only retrieving 2840 tweets
